{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>Verbal Explanation of Spatial Temporal GNNs for Traffic Forecasting</h1>\n",
    "    <h2>Clustering the Explanations of the PeMS-Bay dataset</h2>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook the important subgraphs obtained by the *Explainer* on the *PeMS-Bay* dataset are clustered in order to subdivide it in meaningful events such as congestions or free-flows.\n",
    "\n",
    "Firstly, a distance matrix is obtained for each important subgraph of the datasets in order to compute the spatio-temporal and speed distance among all nodes in the prediction. The distance matrix is obtained throught the method explained in *Revealing the day-to-day regularity of urban congestion patterns with\n",
    "3d speed maps* <a name=\"cite_paper\"></a>[<sup>[1]</sup>](#note_paper)\n",
    "\n",
    "Finally, the important subgraphs are clustered through *Agglomerative Clustering*, while considering the distance matrix as a dissimilarity measure.\n",
    "\n",
    "For more detailed informations about the used functions, look into the corresponding docstrings inside the python files, inside the `src` folder.\n",
    "\n",
    "---\n",
    "<small>\n",
    "\n",
    "<a name=\"note_paper\"></a>[1] \n",
    "C. Lopez et al. “Revealing the day-to-day regularity of urban congestion patterns with\n",
    "3d speed maps”. In: *Scientific Reports, 7(1):14029*, September 2017. ISSN:\n",
    "2045-2322. DOI: 10.1038/s41598-017-14237-8. URL: https://doi.org/10.1038/s41598-017-14237-8.\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the main path in the root folder of the project.\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for autoreloading.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.seed import set_random_seed\n",
    "\n",
    "# Set the random seed for deterministic operations.\n",
    "SEED = 42\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Loading the Data\n",
    "In this section the data is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_DIR = os.path.join('..', 'data', 'pems-bay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_extraction import get_adjacency_matrix\n",
    "\n",
    "# Get the adjacency matrix\n",
    "adj_matrix_structure = get_adjacency_matrix(\n",
    "    os.path.join(BASE_DATA_DIR, 'raw', 'adj_mx_pems_bay.pkl'))\n",
    "\n",
    "# Get the header of the adjacency matrix, the node indices and the\n",
    "# matrix itself.\n",
    "header, node_ids_dict, adj_matrix = adj_matrix_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_extraction import get_locations_dataframe\n",
    "\n",
    "# Get the dataframe containing the latitude and longitude of each sensor.\n",
    "locations_df = get_locations_dataframe(\n",
    "    os.path.join(BASE_DATA_DIR, 'raw', 'graph_sensor_locations_pems_bay.csv'),\n",
    "    has_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the node positions dictionary.\n",
    "node_pos_dict = { i: id for id, i in node_ids_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from src.spatial_temporal_gnn.prediction import predict\n",
    "\n",
    "# Get the data and the values predicted by the STGNN.\n",
    "x_train = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'x_train.npy'))[..., :1]\n",
    "x_val = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'x_val.npy'))[..., :1]\n",
    "x_test = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'x_test.npy'))[..., :1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speeds of the important subgraphs are turned into km/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.config import MPH_TO_KMH_FACTOR\n",
    "\n",
    "# Turn the dataset in kilometers per hour.\n",
    "x_train = x_train * MPH_TO_KMH_FACTOR\n",
    "x_val = x_val * MPH_TO_KMH_FACTOR\n",
    "x_test = x_test * MPH_TO_KMH_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_timesteps, n_nodes, _ = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Distance matrix\n",
    "The distance matrix $M$ used as a metric of dissimilarity in Agglomerative Clustering is computed separately for each instance and is composed of:\n",
    "* A *spatial distance matrix* $M_d$;\n",
    "* A *temporal distance matrix* $M_t$;\n",
    "* A *speed distance matrix* $M_s$\n",
    "\n",
    "The matrices $M_d$, $M_t$ and $M_s$ are each scaled through *min-max scaling* between $0$ and $1$ and summed together in order to obtain $M$ as follows: \n",
    "$$M = W \\cdot M_s + M_d + M_t$$\n",
    "where the speed distance is overweighted by multiplying $M_s$ by a factor $W \\geq 1$ because the speed variable is expected to play a predominant role during the clustering process. $M$ is next normalized again between $0$ and $1$ through min-max scaling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Spatial Distance Matrix\n",
    "The *spatial distance matrix* $M_d$ is an $(N \\cdot T') \\times (N \\cdot T')$ matrix derived from the adjacency matrix of the traffic network $A \\in \\mathbb{R}^{N \\times N}$ and describing the spatial distant of each nodes regardless of their timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explanation.clustering.clustering import (\n",
    "    get_adjacency_distance_matrix)\n",
    "\n",
    "adj_distance_matrix = get_adjacency_distance_matrix(adj_matrix, n_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Adjacency Distance Matrix: (3900, 3900)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the Adjacency Distance Matrix: {adj_distance_matrix.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Temporal Distance Matrix\n",
    "The *temporal distance matrix* $M_t$ is an $(N \\cdot T') \\times (N \\cdot T')$ matrix describing the temporal distance of the nodes at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explanation.clustering.clustering import (\n",
    "    get_temporal_distance_matrix)\n",
    "\n",
    "temporal_distance_matrix = get_temporal_distance_matrix(n_nodes, n_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Temporal Distance Matrix: (3900, 3900)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the Temporal Distance Matrix:',\n",
    "      f'{temporal_distance_matrix.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Speed Distance Matrix\n",
    "The *speed distance matrix* $M_s$ is an $(N \\cdot T') \\times (N \\cdot T')$ matrix describing the speed distance of the nodes at each timestep.\n",
    "\n",
    "It is computed for each instance separately, before Agglomerative Clustering is performed. The value $W$, overweighting it is set as $3$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Clustering Function\n",
    "Next, the clustering technique *Agglomerative Clustering* is used on the distance matrix $M$. It identifies whether each node of the important subgraph, specified by an index in $M$, is part of a distinct traffic cluster.\n",
    "\n",
    "The number of clusters $n$ is tested on a range $[1, 5]$ and $n$ leading to the best score is selected.\n",
    "\n",
    "Score is computed as the ratio between *Cluster Dissimilarity* and *Within Cluster Variance* in order to favor dissimilar clusters with low variance:\n",
    "$$ Score = \\frac{CD}{WCV} $$\n",
    "\n",
    "Within Cluster Variance and Cluster Dissimilarity are computed as follows:\n",
    "* **Within Cluster Variance:**\n",
    "    $$WCV = \\frac{1}{\\sum_{i = 1}^N n_i} \\frac{\\sum_{i = 1}^N n_i \\sigma^2_i}{\\sigma^2} $$\n",
    "    with $N$ the number of clusters, $n_i$ the nodes of the $i^{th}$ cluster in the predicted network and $\\sigma_i^2$ the speed variance among its nodes. $\\sigma^2$ is the variance among all nodes of the prediction.\n",
    "\n",
    "* **Cluster Dissimilarity:**\n",
    "    $$ CD = \\frac{\\sum_{i = 1}^N \\sum_{k = i + 1}^N \\sqrt{n_i \\cdot n_k} \\cdot |\\mu_i - \\mu_k|}{\\sum_{i = 1}^N \\sum_{k = i + 1}^N \\sqrt{n_i \\cdot n_k}} $$\n",
    "    with $\\mu_i$ the mean speed value of cluster $i$.\n",
    "\n",
    "The results are then saved for the train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(BASE_DATA_DIR, 'clustered')\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explanation.clustering.clustering_explanations import get_explanation_clusters_dataset\n",
    "\n",
    "x_train_clustered = get_explanation_clusters_dataset(\n",
    "    x_train,\n",
    "    adj_distance_matrix,\n",
    "    temporal_distance_matrix)\n",
    "\n",
    "np.save(os.path.join(DATA_DIR, 'x_train.npy'), x_train_clustered)\n",
    "\n",
    "x_val_clustered = get_explanation_clusters_dataset(\n",
    "    x_val,\n",
    "    adj_distance_matrix,\n",
    "    temporal_distance_matrix)\n",
    "\n",
    "np.save(os.path.join(DATA_DIR, 'x_val.npy'), x_val_clustered)\n",
    "\n",
    "x_test_clustered = get_explanation_clusters_dataset(\n",
    "    x_test,\n",
    "    adj_distance_matrix,\n",
    "    temporal_distance_matrix)\n",
    "\n",
    "np.save(os.path.join(DATA_DIR, 'x_test.npy'), x_test_clustered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
